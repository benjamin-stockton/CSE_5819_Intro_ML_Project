# Urban Traffic Prediction from Spatio-Temporal Data Using Deep Meta Learning

![[panUrbanTrafficPrediction2019-zotero#Metadata]]

Other files:
* Mdnotes File Name: [[panUrbanTrafficPrediction2019]]
* Metadata File Name: [[panUrbanTrafficPrediction2019-zotero]]

##  Zotero links
* [Local library](zotero://select/items/1_5IE986PY)
* [Cloud library](http://zotero.org/users/4968335/items/5IE986PY)

## Notes
- 

* Mdnotes File Name: [[panUrbanTrafficPrediction2019]]

# Annotations  

# Annotations  
(9/23/2022, 10:08:35 AM)

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%225R4EDB3S%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221720%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B317.955%2C542.293%2C559.717%2C550.892%5D%2C%5B317.955%2C531.334%2C558.212%2C539.933%5D%2C%5B317.955%2C520.375%2C558.199%2C528.974%5D%2C%5B317.955%2C509.416%2C363.116%2C518.015%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221720%22%7D%7D">“Recent advances in data acquisition technologies and mobile computing lead to a collection of large amounts of traffic data, such as vehicle trajectories, enabling much urban analysis and related applications”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221720%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1720</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%222NQKQZ7T%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221720%22%2C%22position%22%3A%7B%22pageIndex%22%3A0%2C%22rects%22%3A%5B%5B317.956%2C137.202%2C558.206%2C146.168%5D%2C%5B317.955%2C126.309%2C559.582%2C134.908%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221720%22%7D%7D">“• Spatial correlations. As the red arrow shown in Figure 1 (a), the traffic of some locations affects mutually and changes all the time.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221720%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1720</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%2293R2GVJH%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221721%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B62.24%2C696.109%2C294.047%2C705.076%5D%2C%5B53.798%2C685.213%2C294.042%2C693.812%5D%2C%5B53.798%2C674.254%2C94.57%2C682.853%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221721%22%7D%7D">“Temporal correlations. Given a location, the current readings of its traffic, such as inflows and outflows, are correlated with its precedents.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221721%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1721</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%2238CF2FH8%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221721%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B63.761%2C623.046%2C294.284%2C631.645%5D%2C%5B53.798%2C612.087%2C286.602%2C620.686%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221721%22%7D%7D">“As both types of correlations affect urban traffic, it is necessary to simultaneously model such spatial and temporal correlations.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221721%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1721</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%22273NKL6H%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221721%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B63.761%2C334.527%2C294.042%2C343.126%5D%2C%5B53.798%2C323.568%2C295.029%2C332.167%5D%2C%5B53.798%2C312.61%2C294.044%2C321.209%5D%2C%5B53.798%2C301.651%2C294.047%2C310.252%5D%2C%5B53.799%2C290.694%2C167.278%2C299.293%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221721%22%7D%7D">“Recently, although there has been significant growth of works for urban traffic prediction as well as analogous ST prediction tasks, the aforementioned challenges are still not tackled well. First of all, some works [15, 22] focus on modeling ST correlations by a single model for all locations.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221721%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1721</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%22A5DJDZ8M%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221721%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B238.371%2C257.817%2C294.059%2C266.416%5D%2C%5B53.798%2C246.856%2C294.045%2C255.455%5D%2C%5B53.798%2C235.897%2C294.042%2C244.496%5D%2C%5B53.798%2C224.938%2C294.046%2C233.537%5D%2C%5B53.798%2C213.979%2C121.16%2C222.578%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221721%22%7D%7D">“Another group of works [16, 23, 28] adopt multi-task learning approaches, which mainly build multiple sub-models for each location and all of these sub-models are trained together by using similarity constraints between locations.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221721%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1721</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%229W39RNWT%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221721%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B63.761%2C159.185%2C294.041%2C167.784%5D%2C%5B53.801%2C148.228%2C294.047%2C156.827%5D%2C%5B53.801%2C137.271%2C118.232%2C145.87%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221721%22%7D%7D">“To tackle the aforementioned challenges, we propose a deep meta learning based framework, entitled ST-MetaNet, for urban traffic prediction.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221721%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1721</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%223D6KJXNA%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221721%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B356.304%2C567.667%2C558.204%2C576.266%5D%2C%5B317.956%2C556.708%2C558.373%2C565.306%5D%2C%5B317.956%2C545.749%2C558.202%2C554.347%5D%2C%5B317.956%2C534.79%2C558.206%2C543.388%5D%2C%5B317.956%2C523.831%2C354.197%2C532.429%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221721%22%7D%7D">“Based on these insights, ST-MetaNet first extracts the meta knowledge (i.e. characteristics) of nodes and edges from their attributes, respectively. The meta knowledge is then used to model the ST correlations, namely, generating weights of the prediction networks.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221721%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1721</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%22XP9RQZ2S%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221721%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B442.291%2C501.913%2C558.2%2C510.511%5D%2C%5B317.956%2C490.954%2C558.203%2C499.552%5D%2C%5B317.956%2C479.997%2C558.202%2C488.595%5D%2C%5B317.956%2C469.036%2C507.263%2C477.634%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221721%22%7D%7D">“ST-MetaNet leverages the meta knowledge extracted from geo-graph attributes to generate the parameter weights of a graph attention network and a recurrent network within sequence-to-sequence architecture.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221721%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1721</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%22WS48QGWW%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221721%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B366.938%2C425.203%2C558.201%2C433.801%5D%2C%5B317.956%2C414.241%2C558.204%2C422.84%5D%2C%5B317.956%2C403.282%2C340.513%2C411.881%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221721%22%7D%7D">“The attention mechanism can capture the dynamic mutual relationship between locations, with regard to their current states.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221721%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1721</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%22ITZJIDNF%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221721%22%2C%22position%22%3A%7B%22pageIndex%22%3A1%2C%22rects%22%3A%5B%5B326.398%2C370.345%2C559.72%2C379.311%5D%2C%5B317.956%2C359.446%2C558.204%2C368.045%5D%2C%5B317.956%2C348.487%2C408.613%2C357.086%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221721%22%7D%7D">“We propose a meta gated recurrent neural network, which generates all weights of a normal gated recurrent unit from the meta knowledge of each node.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221721%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1721</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%22HHEH743Y%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221722%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B63.761%2C445.937%2C298.129%2C456.429%5D%2C%5B53.798%2C436.504%2C294.045%2C445.47%5D%2C%5B53.798%2C424.388%2C234.935%2C435.929%5D%2C%5B229.798%2C424.337%2C266.196%2C435.929%5D%2C%5B261.058%2C423.733%2C290.105%2C434.225%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221722%22%7D%7D">“Problem 1. Given previous τin traffic information (Xt −τin+1, ..., Xt ) and the geo-graph attributes G, predict the traffic information for all locations in the next τout timestamps, denoted as ( ˆ Yt +1, ..., ˆ Yt +τout ).”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221722%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1722</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%22ZSAZR7E7%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221722%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B317.956%2C567.896%2C558.438%2C576.495%5D%2C%5B317.956%2C556.937%2C500.323%2C565.535%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221722%22%7D%7D">“Meta-GAT can capture diverse spatial correlations by individually broadcasting locations’ hidden states along edges.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221722%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1722</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%22GDE9W4IT%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221722%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B317.956%2C502.142%2C558.201%2C510.74%5D%2C%5B317.624%2C491.183%2C490.522%2C499.781%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221722%22%7D%7D">“Meta-RNN can capture diverse temporal correlations associated with the geographical information of locations.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221722%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1722</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%22T6DSQR9A%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221722%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B317.687%2C455.873%2C558.207%2C464.472%5D%2C%5B317.956%2C444.914%2C558.208%2C453.513%5D%2C%5B317.956%2C433.955%2C559.188%2C442.554%5D%2C%5B317.956%2C422.997%2C559.189%2C431.597%5D%2C%5B317.624%2C412.038%2C559.581%2C420.637%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221722%22%7D%7D">“To encode the temporal dynamics of urban traffic, we employ a RNN layer as the first layer of Seq2Seq architecture. There are various types of RNN implementation for time series analysis. Among them, as gated recurrent unit (GRU) [9] is a simple but effective structure, we introduce GRU as a concrete example to illustrate ST-MetaNet.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221722%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1722</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%22SVRRSJ3Z%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221722%22%2C%22position%22%3A%7B%22pageIndex%22%3A2%2C%22rects%22%3A%5B%5B513.326%2C345.942%2C558.202%2C356.086%5D%2C%5B317.956%2C336.223%2C475.075%2C344.822%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221722%22%7D%7D">“GRU derives the vector representations of a hidden state”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221722%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1722</span>)</span>

<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221722%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1722</span>)</span> Overview of the process:  
1a. Encode attributes of edges and nodes of the geo-graph (locations and roads between them) by some sort of dimension reduction in the "meta-knowledge" learner.  
1b. Encode current time data with RNN.  
  
2. Pass all encoded data and the outputs of the initial RNN to the Graph ATtention network to learn the spatial correlations and further embed the data.  
3. Pass the embedded data to another set of RNNs (one for each node) along with the embedded node information to produce final outputs that account for the spatial-temporal autocorrelations at each and between each node.

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%22FTVX7SRG%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221723%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B233.063%2C535.412%2C294.046%2C544.011%5D%2C%5B53.798%2C524.451%2C294.044%2C533.049%5D%2C%5B53.798%2C513.492%2C294.045%2C522.09%5D%2C%5B53.798%2C502.533%2C295.557%2C511.131%5D%2C%5B53.798%2C491.574%2C295.556%2C500.172%5D%2C%5B53.798%2C480.615%2C294.042%2C489.213%5D%2C%5B53.798%2C469.657%2C253.968%2C478.255%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221723%22%7D%7D">“we propose two meta-knowledge learners to learn traffic-related embeddings (meta knowledge) from geographical information, i.e., NMK-Learner and EMK-Learner. As shown in Figure 3 (b), two meta-knowledge learners respectively employ different FCNs, in which input is the attribute of a node or an edge, and the corresponding output is the embedding (vector representation) of that node or edge.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221723%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1723</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%22BBF4GZHI%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221723%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B119.245%2C335.635%2C295.032%2C344.234%5D%2C%5B53.467%2C324.676%2C294.049%2C333.275%5D%2C%5B53.801%2C313.719%2C242.287%2C322.318%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221723%22%7D%7D">“Inspired by graph attention network (GAT) [19], we propose employing attention mechanism into the framework to capture dynamic spatial correlations between nodes.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221723%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1723</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%22UF35MD4C%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221723%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B63.761%2C269.881%2C294.045%2C278.48%5D%2C%5B53.797%2C258.924%2C294.043%2C267.523%5D%2C%5B53.798%2C247.963%2C294.044%2C256.562%5D%2C%5B53.798%2C237.006%2C224.219%2C245.605%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221723%22%7D%7D">“To capture diverse spatial correlations, we propose a meta graph attention network (Meta-GAT) as shown in Figure 4, which employs attention network whose weights are generated from the meta knowledge (embeddings) by the meta learner.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221723%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1723</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%22SWDPRBA8%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221723%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B129.824%2C159.185%2C294.046%2C167.784%5D%2C%5B53.798%2C148.228%2C294.046%2C156.827%5D%2C%5B53.798%2C137.267%2C196.261%2C145.866%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221723%22%7D%7D">“The meta graph attention mechanism for each node mainly contains 2 steps: 1) attention score calculating for each edge; and 2) hidden state aggregation.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221723%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1723</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%22R9AWTCSI%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221723%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B326.398%2C225.295%2C558.201%2C234.262%5D%2C%5B317.956%2C214.397%2C559.156%2C222.996%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221723%22%7D%7D">“Hidden state aggregation. Like GAT, we firstly normalize the attention score for a node across all its neighborhoods by softmax:”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221723%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1723</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%22DB6ZDFNI%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221723%22%2C%22position%22%3A%7B%22pageIndex%22%3A3%2C%22rects%22%3A%5B%5B317.687%2C169.868%2C559.735%2C178.467%5D%2C%5B317.956%2C158.909%2C558.2%2C167.508%5D%2C%5B317.956%2C147.887%2C557.172%2C156.854%5D%2C%5B317.687%2C136.375%2C362.071%2C151.618%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221723%22%7D%7D">“Then for each node, we calculate the overall impact of neighborhoods by linear combinations of the hidden states corresponding to the normalized weights and apply a nonlinearity function σ (e.g., ReLU),”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221723%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1723</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%22I6MAB7SN%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221724%22%2C%22position%22%3A%7B%22pageIndex%22%3A4%2C%22rects%22%3A%5B%5B63.761%2C696.172%2C294.042%2C704.771%5D%2C%5B53.798%2C685.213%2C294.042%2C693.812%5D%2C%5B53.798%2C674.254%2C294.037%2C682.853%5D%2C%5B53.798%2C663.295%2C279.922%2C671.894%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221724%22%7D%7D">“Since we extract meta knowledge from features of locations and edges, and use such information to generate the weights of graph attention network, Meta-GAT can model the inherent relationship between geo-graph attributes and diverse spatial correlations.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221724%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1724</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%22X2VCCHUU%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221724%22%2C%22position%22%3A%7B%22pageIndex%22%3A4%2C%22rects%22%3A%5B%5B142.031%2C349.559%2C294.046%2C360.709%5D%2C%5B53.798%2C340.846%2C295.555%2C349.445%5D%2C%5B53.798%2C329.887%2C294.042%2C338.486%5D%2C%5B53.798%2C317.944%2C295.564%2C327.832%5D%2C%5B53.798%2C307.969%2C294.214%2C316.568%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221724%22%7D%7D">“As a result, all nodes have their individual RNNs respectively, and the models represent the temporal correlations related to the node attributes. In ST-MetaNet, we take the outputs of Meta-GAT as the inputs of Meta-RNN (i.e., Zt ), accordingly, both diverse spatial and temporal correlations are captured.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221724%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1724</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%22ALSS4PK7%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221724%22%2C%22position%22%3A%7B%22pageIndex%22%3A4%2C%22rects%22%3A%5B%5B53.798%2C270.334%2C294.048%2C280.434%5D%2C%5B53.798%2C260.571%2C294.046%2C269.17%5D%2C%5B53.798%2C249.612%2C295.558%2C258.211%5D%2C%5B53.798%2C237.72%2C293.714%2C247.557%5D%2C%5B53.798%2C227.694%2C295.552%2C236.293%5D%2C%5B53.798%2C215.803%2C294.041%2C225.64%5D%2C%5B53.798%2C205.777%2C294.042%2C214.376%5D%2C%5B53.798%2C193.885%2C68.455%2C203.722%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221724%22%7D%7D">“Suppose the loss function for framework training is Ltrain, which measures the difference between the prediction values and the ground truth. We can train ST-MetaNet end-to-end by backpropagation. In specific, there are two types of trainable parameters. Let ω1 denote the trainable parameters in common neural networks (Section 3.1), ω2 denote all trainable parameters in the meta-knowledge learners (Section 3.2), and meta learners (Section 3.3 and Section 3.4).”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221724%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1724</span>)</span>

<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221726%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1726</span>)</span> 286k parameters  
n = 3600  
with 1024x989 node matrix  
and 4114x32 edge matrix  
  
So this is actually potentially a reasonable ratio I'd think. Huge matrices though.

<span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221726%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1726</span>)</span> Why are the number of parameters missing from HA, ARIMA, and GBRT? They have parameters that must be estimated too.

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%22FNRD8KKY%22%2C%22color%22%3A%22%23ffd400%22%2C%22pageLabel%22%3A%221726%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B131.255%2C485.761%2C294.044%2C494.359%5D%2C%5B53.798%2C474.802%2C294.046%2C483.4%5D%2C%5B53.467%2C463.843%2C295.025%2C472.441%5D%2C%5B53.798%2C452.883%2C294.046%2C461.482%5D%2C%5B53.798%2C441.927%2C294.046%2C450.525%5D%2C%5B53.798%2C430.966%2C294.046%2C439.565%5D%2C%5B53.798%2C420.007%2C294.041%2C428.606%5D%2C%5B53.798%2C409.048%2C236.143%2C417.647%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221726%22%7D%7D">“However, as the number of parameters shown in Table 3, ST-MetaNet uses less trainable parameters compared with most of deep models. Particularly in traffic speed prediction, ST-MetaNet uses only 23% trainable parameters compared with DCRNN to obtain better results. This fact is related to the good expressiveness of ST-MetaNet that small dimensional hidden states in Meta-GAT and Meta-GRU can have better representation than larger dimensional hidden states in GAT and GRU.”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221726%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1726</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%222NZ5BLAI%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%221729%22%2C%22position%22%3A%7B%22pageIndex%22%3A9%2C%22rects%22%3A%5B%5B56.718%2C99.78%2C174.137%2C108.038%5D%2C%5B53.798%2C91.368%2C181.9%2C99.626%5D%2C%5B53.798%2C82.956%2C136.597%2C91.214%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221729%22%7D%7D">“https://github.com/panzheyi/ST- MetaNet 2 https://github.com/apache/incubator- mxnet 3 https://github.com/dmlc/dgl”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221729%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1729</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%22QRW8DM2K%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%221730%22%2C%22position%22%3A%7B%22pageIndex%22%3A10%2C%22rects%22%3A%5B%5B62.963%2C340.615%2C199.576%2C349.214%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221730%22%7D%7D">“https://github.com/liyaguang/DCRNN”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221730%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1730</span>)</span>

<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F9Y8748M4%22%2C%22annotationKey%22%3A%223SG8E5TC%22%2C%22color%22%3A%22%232ea8e5%22%2C%22pageLabel%22%3A%221730%22%2C%22position%22%3A%7B%22pageIndex%22%3A10%2C%22rects%22%3A%5B%5B320.876%2C82.957%2C429.298%2C91.215%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221730%22%7D%7D">“https://github.com/liyaguang/DCRNN”</span> <span class="citation" data-citation="%7B%22citationItems%22%3A%5B%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F4968335%2Fitems%2F5IE986PY%22%5D%2C%22locator%22%3A%221730%22%7D%5D%2C%22properties%22%3A%7B%7D%7D">(<span class="citation-item">Pan et al., 2019, p. 1730</span>)</span>

